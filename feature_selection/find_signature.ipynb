{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "is_executing": false
    }
   },
   "outputs": [],
   "source": [
    "import pickle\n",
    "import numpy\n",
    "from time import time\n",
    "numpy.random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "outputs": [],
   "source": [
    "### The words (features) and authors (labels), already largely processed.\n",
    "### These files should have been created from the previous (Lesson 10)\n",
    "### mini-project.\n",
    "words_file = \"../text_learning/your_word_data.pkl\" \n",
    "authors_file = \"../text_learning/your_email_authors.pkl\"\n",
    "word_data = pickle.load( open(words_file, \"r\"))\n",
    "authors = pickle.load( open(authors_file, \"r\") )\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "outputs": [],
   "source": [
    "### test_size is the percentage of events assigned to the test set (the\n",
    "### remainder go into training)\n",
    "### feature matrices changed to dense representations for compatibility with\n",
    "### classifier functions in versions 0.15.2 and earlier\n",
    "from sklearn import cross_validation\n",
    "features_train, features_test, labels_train, labels_test = cross_validation.train_test_split(word_data, authors, test_size=0.1, random_state=42)\n",
    "\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vectorizer = TfidfVectorizer(sublinear_tf=True, max_df=0.5,\n",
    "                             stop_words='english')\n",
    "features_train = vectorizer.fit_transform(features_train)\n",
    "features_test  = vectorizer.transform(features_test).toarray()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "outputs": [],
   "source": [
    "### a classic way to overfit is to use a small number\n",
    "### of data points and a large number of features;\n",
    "### train on only 150 events to put ourselves in this regime\n",
    "features_train = features_train[:150].toarray()\n",
    "labels_train   = labels_train[:150]\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Accuracy (train): 0.9533333333333334\n",
      "Accuracy (test): 0.8162684869169511\n",
      "Training time: 0.112 s\n",
      "Prediction time: 0.378 s\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "### your code goes here\n",
    "### fit and predict ###\n",
    "\n",
    "\n",
    "# Import scikit-learn metrics module for SVC\n",
    "from sklearn import tree\n",
    "# Import scikit-learn metrics module for accuracy calculation\n",
    "from sklearn import metrics\n",
    "\n",
    "# Create a SVC Classifier\n",
    "clf = tree.DecisionTreeClassifier(min_samples_split=40)\n",
    "\n",
    "# Train the model using the training sets\n",
    "t0 = time()\n",
    "clf.fit(features_train, labels_train)\n",
    "training_time = round(time() - t0, 3)\n",
    "\n",
    "# Predict the response for test dataset\n",
    "t0 = time()\n",
    "labels_test_pred = clf.predict(features_test)\n",
    "prediction_time = round(time() - t0, 3)\n",
    "\n",
    "# Model Accuracy, how often is the classifier correct?\n",
    "accuracy = metrics.accuracy_score(labels_test, labels_test_pred)\n",
    "accuracy_train = metrics.accuracy_score(labels_train, clf.predict(features_train))\n",
    "\n",
    "\n",
    "print \"Accuracy (train):\", accuracy_train\n",
    "print \"Accuracy (test):\", accuracy\n",
    "print \"Training time:\", training_time, \"s\"\n",
    "print \"Prediction time:\", prediction_time, \"s\"\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "outputs": [
    {
     "name": "stdout",
     "text": [
      "Feature Ranking: \n",
      "1 feature no.21323 (0.420772351027)\n",
      "2 feature no.18849 (0.216297993167)\n",
      "3 feature no.11975 (0.121936079196)\n",
      "4 feature no.22546 (0.0972784975475)\n",
      "5 feature no.29690 (0.0550565667904)\n",
      "6 feature no.13080 (0.0304094414075)\n",
      "7 feature no.25675 (0.0295406002245)\n",
      "8 feature no.24320 (0.0287084706407)\n",
      "9 feature no.12618 (0.0)\n",
      "10 feature no.12622 (0.0)\n"
     ],
     "output_type": "stream"
    }
   ],
   "source": [
    "importances = clf.feature_importances_\n",
    "\n",
    "import numpy as np\n",
    "indices = np.argsort(importances)[::-1]\n",
    "print 'Feature Ranking: '\n",
    "for i in range(10):\n",
    "    print \"{} feature no.{} ({})\".format(i+1,indices[i],importances[indices[i]])\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "outputs": [
    {
     "data": {
      "text/plain": "u'sshacklsims1rcsntxswbellnet'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 54
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[33614]"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "outputs": [
    {
     "data": {
      "text/plain": "u'cgermanyenroncom'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 55
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[14343]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [
    {
     "data": {
      "text/plain": "u'houectect'"
     },
     "metadata": {},
     "output_type": "execute_result",
     "execution_count": 56
    }
   ],
   "source": [
    "vectorizer.get_feature_names()[21323]\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "outputs": [],
   "source": [
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n",
     "is_executing": false
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  },
  "pycharm": {
   "stem_cell": {
    "cell_type": "raw",
    "source": [],
    "metadata": {
     "collapsed": false
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}